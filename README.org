* streakpy
A Python package for processing and analyzing TREX Streak camera data. 

Main functionality lies in =processing.py=. It works with a command line interface.

** Usage
#+BEGIN_SRC
usage: python processing.py [-h] [-V] [-v] [-c] [-a] [-s] input

positional arguments:
  input                 filepath to .ini file for configuration of inputs

options:
  -h, --help            show this help message and exit
  -V, --version         show program's version number and exit
  -v, --verbosee        print all output
  -c, --calculate_edges run calculate_edges
  -a, --align_edges     run align_edges
  -s, --sum_streaks     run sum_streaks
#+END_SRC

Other files are helper classes for storing and handling the data. =example.ini= is a template for an input configuration file to run processing.py with. Documentation for input config file parameters is a work in progress.

#+begin_example
How does this work?
#+end_example

#+begin_export
Exporting what... exactly?
#+end_export

#+begin_quote
This is a quote. -- Martin Luther
#+end_quote

#+begin_verse
This is a verse???
#+end_verse

#+begin_src
Okay and this is a source block like above.
#+end_src

** Explanation of functions
*** calculate_edges
This algorithm performs edge detection on images in the =full= directory to calculate the bottom edge of each streak in the dataset. First, each image is cropped, has its background gradient removed, and this is saved to the =crop= directory. Then a heavy median filter is applied, followed by a convolution with a horizontal Sobel operator. The resulting image is thresholded based on edge intensity and size, leaving only the most prominent and longest edges. The bottom edge is defined as the bottom-most index of a thresholded edge in each column. This edge goes through filtering to get rid of outliers and is then saved to the =edges= directory.
**** Outputs
- =edges/*.csv=
*** align_edges
This algorithm aligns the calculated edges such as to minimize error from the mean edge. First all edges are roughly vertically aligned based on the polynomial fit at a given horizontal position. Then the mean edge is calculated. Then each edge is receives a vertical micro-shift such as to minimize the weighted error between itself and the mean edge. The error weigthts prioritize error minimization at the bright spots of the images, and are defined by a 1 or 2-Gaussian distribution.
**** Outputs
- =misc/avg_edge.npy=
- =misc/shifts.npy=
- =misc/shifts.csv=
- =misc/edgealignment.png= (if =edge.aligning.save_fig= is =True=)
- =misc/onsettimeerror.png= (if =edge.aligning.save_fig= is =True=)
*** sum_streaks
This algorithm sums the aligned streaks. Streaks that are too close to the top or bottom of the image are ignored. Before summing, a light median filter is applied to each streak. After summing, the collective line of maximum intensity is saved.
**** Outputs
- =misc/streaks.npy=
- =misc/summed.npy=
- =misc/summed.png= (if =streak.summing.save_fig= is =True=)
- =misc/max_intensity_by_column.csv=

** Explanation of config file parameters
*** [paths]
A collection of paths needed to run =processing.py=. Only =full= is required to exist beforehand. =edge=, =crop=, and =misc= will be created if they do not already exist.
- =dir=: [path, optional] Main directory to store all data in. Not used in any code, purely for ease of specifying =full=, =edge=, =crop=, and =misc=.
- =full=: [path] Directory with full raw data.
- =edge=: [path] Directory where calculated edges are stored.
- =crop=: [path] Directory where cropped and background-removed data are stored.
- =misc=: [path] Directory for all other ouputs.

*** [edge.finding]
- =high_percentile_thresh=: [int or float] When thresholding by edge intensity, all points above this percentile will definitely be considered edges.
- =low_percentile_thresh=: [int or float] When thresholding by edge intensity, all points below this percentile will edge not be considered edges.
- =size_thresh=: [int or float] When thresholding by edge size, all edges less than this size will not be considered edges.
- =medfilt_kernel_size=: [int or tuple] The kernel for a median filter applied to the image before edge finding. It is recommended that this be between 9 and 15.
- =degree=: [int]
- =fine_pruning_thresh=: [int]
- =fine_pruning_radius=: [int]
- =simple_xmin=: [int]
- =simple_xmax=: [int]

*** [edge.aligning]
- =align_x=: [int]
- =simple_ythresh=: [int]
- =simple_xthresh=: [int]
- =show_fig=: [bool]
- =save_fig=: [bool]

*** [edge.aligning.weightparameters]
- =mu1=: [float]
- =sigma1=: [float]
- =mu2=: [float, optional]
- =sigma2=: [float, optional]
- =amp2=: [float, optional]

*** [background.processing]
- =average_window_radius=: [int] When removing the background, each column will be subtracted the average value of a =100 x 2*average_window_radius= section from the top of the image, centered at that column. A larger value will follow larger scale structures in the background.
- =crop_bounds=: [tuple] Pixel bounds to that full images will be cropped to before saving to =crop= path. Of the form (=xmin=, =ymin=, =xmax=, =ymax=).
- =medfilt_kernel_size=: [int or tuple] Kernel for median filter applied to the image. It is recommended to use a horizontal kernel such as (1,5) to smooth in the energy axis (x) but not time (y).

*** [streak.summing]
- =num=: [int, optional] The number of files to sum from =crop= directory. Useful if you don't want to run the entire directory.
- =streak_height=: [int]
- =show_fig=: [bool] Whether to show the figure of all streaks summed.
- =save_fig=: [bool] Whether to save the figure of all streaks summed.
